{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911de2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_model.ipynb\\n\\nPurpose\\n-------\\n    Implement and train a manual Random Forest classifier from scratch \\n    to predict diabetes risk levels based on health and lifestyle data.\\n\\nDescription\\n-----------\\n    This notebook includes:\\n    1. Node, Decision Tree, and Random Forest class implementations \\n       using Gini impurity.\\n    2. Utility methods for tree construction, bootstrap sampling, \\n       feature selection, and majority voting.\\n    3. Loading and splitting the diabetes dataset into training and test sets.\\n    4. Training the Random Forest model and evaluating accuracy on both sets.\\n    5. Saving the trained model as 'model.pkl' for backend integration.\\n\\nUsage\\n-----\\n    Run the notebook or script to train and save the model. \\n    The saved 'model.pkl' is later used by the backend \\n    to predict diabetes risk for new user inputs.\\n\\nDependencies\\n------------\\n    - numpy\\n    - pandas\\n    - dill\\n    - collections\\n    - typing\\n    - pathlib\\n\\nAuthor\\n------\\n    Waseem Alyazidi.\\n\\nDate\\n----\\n    2025-09-08.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_model.ipynb\n",
    "\n",
    "Purpose\n",
    "-------\n",
    "    Implement and train a manual Random Forest classifier from scratch \n",
    "    to predict diabetes risk levels based on health and lifestyle data.\n",
    "\n",
    "Description\n",
    "-----------\n",
    "    This notebook includes:\n",
    "    1. Node, Decision Tree, and Random Forest class implementations \n",
    "       using Gini impurity.\n",
    "    2. Utility methods for tree construction, bootstrap sampling, \n",
    "       feature selection, and majority voting.\n",
    "    3. Loading and splitting the diabetes dataset into training and test sets.\n",
    "    4. Training the Random Forest model and evaluating accuracy on both sets.\n",
    "    5. Saving the trained model as 'model.pkl' for backend integration.\n",
    "\n",
    "Usage\n",
    "-----\n",
    "    Run the notebook or script to train and save the model. \n",
    "    The saved 'model.pkl' is later used by the backend \n",
    "    to predict diabetes risk for new user inputs.\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - dill\n",
    "    - collections\n",
    "    - typing\n",
    "    - pathlib\n",
    "\n",
    "Author\n",
    "------\n",
    "    Waseem Alyazidi.\n",
    "\n",
    "Date\n",
    "----\n",
    "    2025-09-08.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4c9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import Tuple, Any, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842bc716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "class Node:\n",
    "    def __init__(self, feature_index: Optional[int], threshold: Optional[float], left_child: Optional[\"Node\"],\n",
    "                 right_child: Optional[\"Node\"], value: Optional[int]) -> None:\n",
    "        self.feature_index: Optional[int] = feature_index\n",
    "        self.threshold: Optional[float] = threshold\n",
    "        self.left_child: Optional[\"Node\"] = left_child\n",
    "        self.right_child: Optional[\"Node\"] = right_child\n",
    "        self.value: Optional[int] = value\n",
    "    \n",
    "    def is_leaf(self) -> bool:\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4337986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Decision Tree\n",
    "class ManualDecisionTree:\n",
    "    def __init__(self, max_depth: int = 10, min_samples_split: int = 2,\n",
    "                 max_features: Optional[int] = None, random_state: Optional[int] = None) -> None:\n",
    "        self.max_depth: int = max_depth\n",
    "        self.min_samples_split: int = min_samples_split\n",
    "        self.max_features: Optional[int] = max_features\n",
    "        self.random_state: Optional[int] = random_state\n",
    "        self._rng: np.random.Generator = np.random.default_rng(random_state) # reproducibility\n",
    "        self.root: Optional[Node] = None\n",
    "    \n",
    "\n",
    "    # Fit data to the model\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "            Fit training data to the model.\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray): Samples matrix with shape (n_samples, n_features).\n",
    "                y (np.ndarray): Target vector with shape (n_samples,).\n",
    "            \n",
    "            Raises:\n",
    "                ValueError: If X or y is empty, or if number of samples mismatch.\n",
    "                TypeError: If X contains non-numeric features.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        if y.ndim >= 2:\n",
    "            y = y.ravel() # Reshape y to 1D matrix\n",
    "        \n",
    "        if X.size == 0 or y.size == 0:\n",
    "            raise ValueError(f\"X or y is empty matrix. Got X: {X.size}, y: {y.size}.\")\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"X and y must have the same number of samples. Got X: {X.shape[0]}, y: {y.shape[0]}\\n\")\n",
    "        \n",
    "        if not np.issubdtype(X.dtype, np.number):\n",
    "            raise TypeError(f\"All features must be numeric.\\n\")\n",
    "        \n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "    \n",
    "\n",
    "    # Build the tree recursively\n",
    "    def _build_tree(self, X: np.ndarray, y: np.ndarray, depth: int) -> Node:\n",
    "        \"\"\"\n",
    "            Recursively build the decision tree.\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray): Samples matrix (n_samples, n_features).\n",
    "                y (np.ndarray): Target vector (n_samples,).\n",
    "                depth (int): Current depth of the tree.\n",
    "\n",
    "            Returns:\n",
    "                Node: A Node object, either a leaf node or internal node with left/right children.\n",
    "        \"\"\"\n",
    "        # Stop condition (leaf)\n",
    "        if depth >= self.max_depth or np.unique(y).size == 1 or y.size < self.min_samples_split:\n",
    "            return Node(feature_index=None, threshold=None, left_child=None,\n",
    "                        right_child=None, value=self._most_common(y))\n",
    "        \n",
    "        feature_index, threshold, X_left, y_left, X_right, y_right = self._best_split(X, y)\n",
    "\n",
    "        if feature_index is None: # Fallback. No split found\n",
    "            return Node(feature_index=None, threshold=None, left_child=None,\n",
    "                        right_child=None, value=self._most_common(y))\n",
    "\n",
    "        left_subtree: Node = self._build_tree(X_left, y_left, depth + 1)\n",
    "        right_subtree: Node = self._build_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return Node(\n",
    "            feature_index=feature_index,\n",
    "            threshold=threshold,\n",
    "            left_child=left_subtree,\n",
    "            right_child=right_subtree,\n",
    "            value=None\n",
    "        )\n",
    "    \n",
    "\n",
    "    # Find the best split\n",
    "    def _best_split(self, X: np.ndarray, y: np.ndarray) -> Tuple[\n",
    "        Optional[int],\n",
    "        Optional[float],\n",
    "        Optional[np.ndarray],\n",
    "        Optional[np.ndarray],\n",
    "        Optional[np.ndarray],\n",
    "        Optional[np.ndarray]\n",
    "    ]:\n",
    "        \"\"\"\n",
    "            Find the best split in the dataset by minimizing Gini impurity.\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray): Feature matrix of shape (n_samples, n_features).\n",
    "                y (np.ndarray): Target vector of shape (n_samples,).\n",
    "\n",
    "            Returns:\n",
    "                Tuple containing:\n",
    "                    - feature_index (int or None): Index of the best feature to split on.\n",
    "                    - threshold (float or None): Threshold value for the split.\n",
    "                    - X_left (np.ndarray or None): Subset of features for left split.\n",
    "                    - y_left (np.ndarray or None): Subset of targets for left split.\n",
    "                    - X_right (np.ndarray or None): Subset of features for right split.\n",
    "                    - y_right (np.ndarray or None): Subset of targets for right split.\n",
    "            \"\"\"\n",
    "        best_gini: float = float(\"inf\")\n",
    "        best_split: Tuple[Any] = (None, None, None, None, None, None)\n",
    "        n_features: int = X.shape[1]\n",
    "\n",
    "        # Feature subset (if max_features is set)\n",
    "        if self.max_features is None:\n",
    "            feature_indices: np.ndarray = np.arange(n_features)\n",
    "        else:\n",
    "            max_features: int = min(self.max_features, n_features)\n",
    "            feature_indices: np.ndarray = self._rng.choice(n_features, size=max_features, replace=False)\n",
    "\n",
    "        # Loop over each feature\n",
    "        for feature_index in feature_indices:\n",
    "            unique_values: np.ndarray = np.unique(X[:, feature_index])\n",
    "            if unique_values.size <= 1:\n",
    "                continue\n",
    "            thresholds: np.ndarray = (unique_values[:-1] + unique_values[1:]) /2\n",
    "\n",
    "            # Loop over thresholds\n",
    "            for threshold in thresholds:\n",
    "                left_indices: np.ndarray = X[:, feature_index] < threshold\n",
    "                right_indices: np.ndarray = ~left_indices # Inverse of left_indices\n",
    "\n",
    "                if left_indices.sum() == 0 or right_indices.sum() == 0:\n",
    "                    continue\n",
    "                # Split labels\n",
    "                left_labels, right_labels = y[left_indices], y[right_indices]\n",
    "                \n",
    "                # Calculate gini\n",
    "                gini_left: float = self._gini(left_labels)\n",
    "                gini_right: float = self._gini(right_labels)\n",
    "                weighted_gini: float = ((left_labels.size * gini_left) + (right_labels.size * gini_right)) / y.size\n",
    "\n",
    "                # Update best split\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_split = (feature_index, threshold, X[left_indices], left_labels, X[right_indices], right_labels)\n",
    "        return best_split\n",
    "    \n",
    "    \n",
    "    # Calculate gini\n",
    "    def _gini(self, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "            Calculate gini.\n",
    "\n",
    "            Parameters:\n",
    "                y (np.ndarray): Targets matrix with shape (n_samples,).\n",
    "            \n",
    "            Returns:\n",
    "                float: The gini.\n",
    "        \"\"\"\n",
    "        _,counts = np.unique(y, return_counts=True)\n",
    "        prob: np.ndarray = counts / counts.sum()\n",
    "        return 1 - np.sum(prob **2)\n",
    "\n",
    "\n",
    "    # Most common label\n",
    "    def _most_common(self, y: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "            Find the most common label in y matrix.\n",
    "\n",
    "            Parameters:\n",
    "                y (np.ndarray): Targets matrix with shape (n_samples,).\n",
    "            \n",
    "            Returns:\n",
    "                int: The label.\n",
    "        \"\"\"\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "    \n",
    "\n",
    "    # Prediction\n",
    "    def predict(self, X_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Predict on the new given data.\n",
    "\n",
    "            Parameters:\n",
    "                X_new (np.ndarray): New samples matrix to predict on, with shape (n_samples, n_features).\n",
    "            \n",
    "            Returns:\n",
    "                np.ndarray: A matrix with predictions.\n",
    "        \"\"\"\n",
    "        X_new: np.ndarray = np.asarray(X_new)\n",
    "        if X_new.ndim == 1:\n",
    "            X_new = X_new.reshape(1, -1)\n",
    "        if X_new.size == 0:\n",
    "            raise ValueError(\"The given X matrix is empty.\\n\")\n",
    "        if not np.issubdtype(X_new.dtype, np.number):\n",
    "            raise TypeError(f\"All features must be numeric.\\n\")\n",
    "        \n",
    "        if self.root is None:\n",
    "            raise ValueError(\"The model has not been trained! Please call 'fit()' first.\\n\")\n",
    "        \n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X_new])\n",
    "\n",
    "    # Traverse tree\n",
    "    def _traverse_tree(self, X_new: np.ndarray, node: Node) -> int:\n",
    "        \"\"\"\n",
    "            Traverse the tree until a leaf node is reached.\n",
    "\n",
    "            Parameters:\n",
    "                X_new (np.ndarray): New samples matrix to predict on, with shape (n_samples, n_features).\n",
    "                node (Node): Current node in the tree.\n",
    "            \n",
    "            Returns:\n",
    "                int: The predicted label.\n",
    "        \"\"\"\n",
    "        X_new: np.ndarray = np.asarray(X_new)\n",
    "        if X_new.ndim > 1:\n",
    "            if X_new.shape[0] == 1:\n",
    "                X_new = X_new[0]\n",
    "            else:\n",
    "                raise ValueError(\"Expected single sample (1D) in _traverse_tree.\")\n",
    "\n",
    "        # Leaf conditions\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if node.left_child is None or node.right_child is None:\n",
    "            return node.value  # fallback\n",
    "        if node.feature_index is None or node.feature_index >= X_new.size:\n",
    "            return node.value\n",
    "        \n",
    "        if X_new[node.feature_index] < node.threshold:\n",
    "            return self._traverse_tree(X_new, node.left_child)\n",
    "        else:\n",
    "            return self._traverse_tree(X_new, node.right_child)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63aec1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Random Forest\n",
    "class ManualRandomForest:\n",
    "    def __init__(self, n_trees: int = 100, max_depth: int = 10,\n",
    "                 min_samples_split: int = 2, max_features: Optional[int] = None,\n",
    "                 random_state: Optional[int] = None) -> None:\n",
    "        self.n_trees: int = n_trees\n",
    "        self.max_depth: int = max_depth\n",
    "        self.min_samples_split: int = min_samples_split\n",
    "        self.max_features: Optional[int] = max_features\n",
    "        self.random_state: Optional[int] = random_state\n",
    "        self._rng: np.random.Generator = np.random.default_rng(random_state) # reproducibility\n",
    "        self.trees: List[ManualDecisionTree] = []\n",
    "    \n",
    "    # Fit data to the model\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "            Fit training data to the model.\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray): Samples matrix with shape (n_samples, n_features).\n",
    "                y (np.ndarray): Target vector with shape (n_samples,).\n",
    "            \n",
    "            Raises:\n",
    "                ValueError: If X or y is empty, or if number of samples mismatch.\n",
    "                TypeError: If X contains non-numeric features.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        if y.ndim >= 2:\n",
    "            y = y.ravel() # Reshape y to 1D matrix\n",
    "        \n",
    "        if X.size == 0 or y.size == 0:\n",
    "            raise ValueError(f\"X or y is empty matrix. Got X: {X.size}, y: {y.size}.\")\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"X and y must have the same number of samples. Got X: {X.shape[0]}, y: {y.shape[0]}\\n\")\n",
    "        \n",
    "        if not np.issubdtype(X.dtype, np.number):\n",
    "            raise TypeError(f\"All features must be numeric.\\n\")\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            X_sample, y_sample = self._bootstrap_samples(X, y)\n",
    "\n",
    "            tree_seed: int = int(self._rng.integers(0, 1e9))\n",
    "            tree: ManualDecisionTree = ManualDecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_features=self.max_features,\n",
    "                random_state=int(tree_seed)\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "\n",
    "    # Generate bootstrap samples (sampling with replacement)\n",
    "    def _bootstrap_samples(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "            Generate bootstrap samples (sampling with replacement).\n",
    "\n",
    "            Parameters:\n",
    "                X (np.ndarray): Feature matrix (n_samples, n_features).\n",
    "                y (np.ndarray): Target vector (n_samples,).\n",
    "\n",
    "            Returns:\n",
    "                Tuple[np.ndarray, np.ndarray]: Bootstrapped X and y samples.\n",
    "        \"\"\"\n",
    "        n_samples: int = X.shape[0]\n",
    "\n",
    "        # Randomly select indices with replacement (bootstrap sampling)\n",
    "        indices: np.ndarray = self._rng.choice(n_samples, size=n_samples, replace=True)\n",
    "\n",
    "        # Use the selected indices to create the bootstrap sample\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    # Collect trees predictions\n",
    "    def _collect_trees_predictions(self, X_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Collect predictions from all decision trees.\n",
    "\n",
    "            Parameters:\n",
    "                X_new (np.ndarray): New data samples (n_samples, n_features).\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Predictions of shape (n_trees, n_samples).\n",
    "        \"\"\"\n",
    "        return np.array([tree.predict(X_new) for tree in self.trees])\n",
    "\n",
    "\n",
    "    # Determine the final result by majority vote\n",
    "    def _majority_vote(self, predictions: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Aggregate predictions from trees using majority vote.\n",
    "\n",
    "            Parameters:\n",
    "                predictions (np.ndarray): Predictions from all trees (n_trees, n_samples).\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Final predictions (n_samples,).\n",
    "        \"\"\"\n",
    "        predictions = predictions.T # Convert shape to (n_samples, n_trees)\n",
    "        final_predictions: List[int] = [\n",
    "            Counter(sample_pred).most_common(1)[0][0] for sample_pred in predictions\n",
    "        ]\n",
    "        return np.array(final_predictions)\n",
    "    \n",
    "\n",
    "    # Predictions\n",
    "    def predict(self, X_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Predict target values for new samples.\n",
    "\n",
    "            Parameters:\n",
    "                X_new (np.ndarray): New data samples (n_samples, n_features).\n",
    "\n",
    "            Returns:\n",
    "                np.ndarray: Predicted labels (n_samples,).\n",
    "        \"\"\"\n",
    "        if not self.trees:\n",
    "            raise ValueError(\"The model has not been trained! Call 'fit()' first.\\n\")\n",
    "        predictions: np.ndarray = self._collect_trees_predictions(X_new)\n",
    "        return self._majority_vote(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b6d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9984.\n",
      "Test Accuracy: 0.8170.\n",
      "\n",
      "Average Accuracy: 0.91.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root folder to sys.path\n",
    "project_root = Path(\"..\").resolve()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill\n",
    "from backend.utils import load_csv_data, train_test_split\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Testing and saving the model.\"\"\"\n",
    "\n",
    "    # Load and split the data\n",
    "    df: pd.DataFrame = load_csv_data(source_path=r\"../data/diabetes.csv\")\n",
    "    X_train, y_train, X_test, y_test = train_test_split(df, test_size=0.2, target_col=\"risk_level\", random_state=42)\n",
    "\n",
    "    # Train and test the model\n",
    "    rf_model: ManualRandomForest = ManualRandomForest(\n",
    "        n_trees=100,\n",
    "        max_depth=9,\n",
    "        min_samples_split=2,\n",
    "        max_features=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    # Save the trained model.\n",
    "    with open(r\"../backend/model.pkl\", mode=\"wb\") as f:\n",
    "        dill.dump(rf_model, f)\n",
    "\n",
    "    train_pred: np.ndarray = rf_model.predict(X_train)\n",
    "    test_pred: np.ndarray = rf_model.predict(X_test)\n",
    "\n",
    "    train_acc: np.ndarray = np.sum(train_pred == y_train) / y_train.size\n",
    "    test_acc: np.ndarray = np.sum(test_pred == y_test) / y_test.size\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}.\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}.\\n\")\n",
    "    print(f\"Average Accuracy: {(train_acc+test_acc)/2.0:.2f}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
